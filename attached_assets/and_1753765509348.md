<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# and

Here's the OpenRouter API documentation reformatted to be Replit Agent friendly:

## OpenRouter API for Replit Agent

**Quick Setup (Agent-Ready)**
Copy this setup code for immediate use:

```python
import requests
import json

# Configuration
API_KEY = "YOUR_OPENROUTER_KEY"  # Get from openrouter.ai dashboard
BASE_URL = "https://openrouter.ai/api/v1"
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}
```


### **Essential Endpoints**

**1. Chat Completions** (Primary endpoint)

```python
def chat_completion(model, messages, max_tokens=1000):
    url = f"{BASE_URL}/chat/completions"
    payload = {
        "model": model,  # Use full model name from /models
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.7
    }
    response = requests.post(url, headers=HEADERS, json=payload)
    return response.json()
```

**2. List Available Models**

```python
def get_models():
    url = f"{BASE_URL}/models"
    response = requests.get(url, headers=HEADERS)
    return response.json()["data"]
```


### **Agent-Friendly Model Selection**

**Popular Models by Use Case:**

- **Fast/Cheap**: `"openai/gpt-3.5-turbo"`[^1]
- **Balanced**: `"anthropic/claude-3-haiku"`[^1]
- **Creative**: `"openai/gpt-4"`[^1]
- **Code**: `"meta-llama/codellama-34b-instruct"`[^1]
- **Open Source**: `"mistralai/mixtral-8x7b-instruct"`[^1]

**Auto-Fallback** (Recommended for agents):

```python
# Agent will try models in order if first is unavailable
models = [
    "openai/gpt-4",
    "anthropic/claude-3-sonnet", 
    "openai/gpt-3.5-turbo"
]
```


### **Replit Agent Best Practices**

**1. Clear Prompting**[^2][^3]

```python
messages = [
    {"role": "system", "content": "You are a helpful coding assistant."},
    {"role": "user", "content": "Create a Python function that validates email addresses"}
]
```

**2. Error Handling for Agents**

```python
def safe_api_call(model, messages):
    try:
        response = chat_completion(model, messages)
        if "error" in response:
            return f"API Error: {response['error']['message']}"
        return response["choices"][^0]["message"]["content"]
    except Exception as e:
        return f"Request failed: {str(e)}"
```

**3. Token Management**

```python
# Check token limits per model
def get_model_info(model_name):
    models = get_models()
    for model in models:
        if model["id"] == model_name:
            return {
                "context_length": model["context_length"],
                "pricing": model["pricing"]
            }
```


### **Streaming for Real-Time Agents**

```python
def stream_response(model, messages):
    url = f"{BASE_URL}/chat/completions"
    payload = {
        "model": model,
        "messages": messages,
        "stream": True
    }
    headers = {**HEADERS, "Accept": "text/event-stream"}
    
    response = requests.post(url, headers=headers, json=payload, stream=True)
    for line in response.iter_lines():
        if line.startswith(b"data: "):
            data = line[6:]  # Remove "data: " prefix
            if data != b"[DONE]":
                yield json.loads(data)
```


### **Agent Integration Tips**

**Environment Variables** (Replit Secrets)

```python
import os
API_KEY = os.environ.get("OPENROUTER_API_KEY")
```

**Rate Limiting** (3 req/s default)[^1]

```python
import time
time.sleep(0.34)  # Simple rate limiting between calls
```

**Cost Tracking**

```python
def track_usage(response):
    if "usage" in response:
        tokens_used = response["usage"]["total_tokens"]
        print(f"Tokens used: {tokens_used}")
```


### **Complete Agent Example**

```python
class OpenRouterAgent:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://openrouter.ai/api/v1"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def chat(self, prompt, model="openai/gpt-3.5-turbo"):
        messages = [{"role": "user", "content": prompt}]
        response = self.chat_completion(model, messages)
        return response["choices"][^0]["message"]["content"]
    
    def chat_completion(self, model, messages):
        # Implementation from above
        pass
```


### **Migration from OpenAI**

**Change these 3 lines only:**

1. Base URL: `https://openrouter.ai/api/v1`
2. API Key: Your OpenRouter key
3. Model names: Full qualified names (e.g., `"openai/gpt-4"`)

Everything else stays the same - perfect for existing agent codebases[^1][^4].

<div style="text-align: center">‚ÅÇ</div>

[^1]: https://docs.replit.com/replitai/agent

[^2]: https://www.linkedin.com/pulse/unlocking-replit-agents-full-potential-developers-guide-wecncode-otsvf

[^3]: https://docs.replit.com/tutorials/effective-prompting

[^4]: https://neon.com/guides/replit-neon

[^5]: https://replit.com/ai

[^6]: https://www.datacamp.com/tutorial/replit-agent-ai-code-editor

[^7]: https://replit.com/builds/ai-agent

[^8]: https://bakingai.com/blog/replit-agent-ai-coding-revolution/

[^9]: https://www.youtube.com/watch?v=FpzJL5085iQ

[^10]: https://www.newline.co/@kchan/replit-agent-an-introductory-guide--2788d5a5

[^11]: https://blog.replit.com/ai-agents-code-execution

[^12]: https://www.youtube.com/watch?v=VXrVVUPst0w

[^13]: https://www.youtube.com/watch?v=IIFb08rLpOg

[^14]: https://www.reddit.com/r/ChatGPTCoding/comments/1jrp1tj/a_simple_guide_to_setting_up_gemini_25_pro_free/

[^15]: https://replit.com

[^16]: https://www.reddit.com/r/replit/comments/1ib51qg/lets_share_your_best_tips_for_replit_below_and/

[^17]: https://www.youtube.com/watch?v=SOjE5sfPk6M

[^18]: https://openrouter.ai/docs/quickstart

[^19]: https://github.com/langchain-ai/open_deep_research/issues/75

[^20]: https://www.reddit.com/r/comfyui/comments/1i9mnmd/openrouter_api_for_comfyui/

